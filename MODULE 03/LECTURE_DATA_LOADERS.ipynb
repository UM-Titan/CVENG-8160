{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1GGJAU7J1H0hbduoOjS8PW-D_oYKP09ib","authorship_tag":"ABX9TyNqnfgmLq6+PuoJcPu9tgOY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["%cd '/content/drive/MyDrive/classes/CVENG_8160/SPRING_2024/Pytorch Introduction'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZiOrWy4f8m2T","executionInfo":{"status":"ok","timestamp":1706647238634,"user_tz":360,"elapsed":983,"user":{"displayName":"Yaw Adu-Gyamfi","userId":"06648105294395810325"}},"outputId":"39093754-4c35-4783-9cd8-34807fb34767"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/classes/CVENG_8160/SPRING_2024/Pytorch Introduction\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"erfc3zDm8Kx2","executionInfo":{"status":"ok","timestamp":1706647251569,"user_tz":360,"elapsed":10038,"user":{"displayName":"Yaw Adu-Gyamfi","userId":"06648105294395810325"}},"outputId":"cf0e57d9-fb59-45e1-e121-9256d7c7c6a9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<contextlib.ExitStack at 0x7db0bd483a00>"]},"metadata":{},"execution_count":2}],"source":["import os\n","import torch\n","import pandas as pd\n","from skimage import io, transform\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","from pathlib import Path\n","from PIL import Image\n","# Ignore warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","plt.ion()   # interactive mode"]},{"cell_type":"code","source":["class traffic_sign(Dataset):\n","    def __init__(self, *args):\n","\n","        # initialize dataset variables here\n","        print ('initialize')\n","\n","    def __len__(self):\n","        # returns the length of the dataset\n","        return None\n","\n","    def __getitem__(self, index):\n","\n","        # preprocess and transformations\n","        # indexes the dataset such that dataset[i] can retrieve the ith sample.\n","        return image, label"],"metadata":{"id":"8J6EreiPFAM-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class traffic_sign(Dataset):\n","    def __init__(self, root_dir ):\n","\n","        # initialize dataset variables here\n","        # self.root = root_dir\n","        self.root = Path(root_dir)\n","\n","        self.df = pd.DataFrame(columns = ['image_names','class_label'])\n","\n","        for fldr in self.root.iterdir():\n","          img_names = []\n","          if fldr.is_dir():\n","            img_names = img_names + list(fldr.glob('*.ppm'))\n","\n","          img_names = [i for i in img_names]\n","          df_cur = pd.DataFrame(img_names,columns = ['image_names'])\n","          df_cur['class_label'] = fldr.name\n","          self.df = pd.concat([self.df, df_cur],axis=0)\n","\n","        self.df = self.df.sample(frac=1)\n","        self.image_names = list(self.df['image_names'].values)\n","        self.class_label = list(self.df['class_label'].values)\n","\n","\n","    def __len__(self):\n","        # returns the length of the dataset\n","        return len(self.image_names)\n","\n","    def __getitem__(self, idx):\n","\n","        # preprocess and transformations\n","        # indexes the dataset such that dataset[i] can retrieve the ith sample.\n","        image = self.image_names[idx]\n","        image_data = io.imread(image)\n","        # image_np = Image.fromarray(image_data)\n","\n","        label = self.class_label[idx]\n","\n","        sample = {'image': image_data, 'label': label}\n","\n","        return sample"],"metadata":{"id":"DJZOKuqqFAPb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# traffic_sign_dataset = traffic_sign('data/traffic_signs_class')"],"metadata":{"id":"honqEnlu_NuR","executionInfo":{"status":"ok","timestamp":1706652409102,"user_tz":360,"elapsed":177,"user":{"displayName":"Yaw Adu-Gyamfi","userId":"06648105294395810325"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# fig = plt.figure(figsize=(20,20))\n","# ncols = 8\n","# for i, sample in enumerate(traffic_sign_dataset):\n","#   print(i, sample['image'].shape, sample['label'])\n","#   ax = plt.subplot(1, ncols, i + 1)\n","#   plt.tight_layout()\n","#   ax.set_title('Sample #{} - {}'.format(i, sample['label']))\n","#   ax.axis('off')\n","#   # show_landmarks(**sample)\n","#   plt.imshow(sample['image'])\n","\n","#   if i == ncols-1:\n","#       plt.show()\n","#       break"],"metadata":{"id":"C4z0C35NL28q","executionInfo":{"status":"ok","timestamp":1706652407497,"user_tz":360,"elapsed":7,"user":{"displayName":"Yaw Adu-Gyamfi","userId":"06648105294395810325"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["## transform data\n","class Rescale(object):\n","    \"\"\"Rescale the image in a sample to a given size.\n","\n","    Args:\n","        output_size (tuple or int): Desired output size. If tuple, output is\n","            matched to output_size. If int, smaller of image edges is matched\n","            to output_size keeping aspect ratio the same.\n","    \"\"\"\n","\n","    def __init__(self, output_size):\n","        assert isinstance(output_size, (int, tuple))\n","        self.output_size = output_size\n","\n","    def __call__(self, sample):\n","        image, labels = sample['image'], sample['label']\n","\n","        h, w = image.shape[:2]\n","\n","        if isinstance(self.output_size, int):\n","            if h > w:\n","                new_h, new_w = self.output_size * h / w, self.output_size\n","            else:\n","                new_h, new_w = self.output_size, self.output_size * w / h\n","        else:\n","            new_h, new_w = self.output_size\n","\n","        new_h, new_w = int(new_h), int(new_w)\n","\n","        img = transform.resize(image, (new_h, new_w))\n","\n","        return {'image': img, 'label': labels}"],"metadata":{"id":"3hqIvp2TGiOG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# out_img = scale(traffic_sign_dataset[500])"],"metadata":{"id":"T-UVVoZ7Op5E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import time\n","# composed = transforms.Compose([Rescale(256), Flip(0)])\n","# for i,trnsfm in enumerate([Flip(1), Rescale(128),composed]):\n","#   print (type(trnsfm).__name__)\n","#   # print (trnsfm(traffic_sign_dataset[500]))\n","\n","#   ax = plt.subplot(1, 3, i + 1)\n","#   plt.imshow(trnsfm(traffic_sign_dataset[500])['image'])\n","#   plt.tight_layout()\n","#   ax.set_title(type(trnsfm).__name__)"],"metadata":{"id":"VApPEVfCPZ5E","executionInfo":{"status":"ok","timestamp":1706652506123,"user_tz":360,"elapsed":126,"user":{"displayName":"Yaw Adu-Gyamfi","userId":"06648105294395810325"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["## write a class to flip the image from left  to right"],"metadata":{"id":"iFnUugZPaWqy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## write a class to convert image to tensor"],"metadata":{"id":"rfOPUYQZYVxj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TrafficSignDataset(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","\n","        # initialize dataset variables here\n","        # self.root = root_dir\n","        self.root = Path(root_dir)\n","        self.transform = transform\n","\n","        self.df = pd.DataFrame(columns = ['image_names','class_label'])\n","\n","        for fldr in self.root.iterdir():\n","          img_names = []\n","          if fldr.is_dir():\n","            img_names = img_names + list(fldr.glob('*.ppm'))\n","\n","          img_names = [i for i in img_names]\n","          df_cur = pd.DataFrame(img_names,columns = ['image_names'])\n","          df_cur['class_label'] = fldr.name\n","          self.df = pd.concat([self.df, df_cur],axis=0)\n","\n","        self.df = self.df.sample(frac=1)\n","        self.image_names = list(self.df['image_names'].values)\n","        self.class_label = list(self.df['class_label'].values)\n","\n","\n","    def __len__(self):\n","        # returns the length of the dataset\n","        return len(self.image_names)\n","\n","    def __getitem__(self, idx):\n","\n","        # preprocess and transformations\n","        # indexes the dataset such that dataset[i] can retrieve the ith sample.\n","        image = self.image_names[idx]\n","        image_data = io.imread(image)\n","        # image_np = Image.fromarray(image_data)\n","\n","        label = self.class_label[idx]\n","\n","        sample = {'image': image_data, 'label': label}\n","\n","        if self.transform:\n","            sample = self.transform(sample)\n","\n","        return sample"],"metadata":{"id":"Sj78YKBAVmXu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["compose_transforms = transforms.Compose([Rescale((256,256)), Flip(0)])\n","traffic_obj = TrafficSignDataset('data/traffic_signs_class',transform=compose_transforms)"],"metadata":{"id":"wgO2V4fdWFE5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i,ts in enumerate(traffic_obj):\n","  print (ts['image'].shape)\n","  if i == 5:\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u5DPHU9lWew4","executionInfo":{"status":"ok","timestamp":1706651526483,"user_tz":360,"elapsed":269,"user":{"displayName":"Yaw Adu-Gyamfi","userId":"06648105294395810325"}},"outputId":"57516576-2788-4c9c-83d9-985a9de34192"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(256, 256, 3)\n","(256, 256, 3)\n","(256, 256, 3)\n","(256, 256, 3)\n","(256, 256, 3)\n","(256, 256, 3)\n"]}]}]}